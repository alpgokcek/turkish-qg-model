@article{chali-hasan-2015-towards,
	title= "Towards Topic-to-Question Generation",
	author = "Chali, Yllias  and Hasan, Sadid A.",
	journal = "Computational Linguistics",
	volume = 41,
	number = 1,
	month = mar,
	year = "2015",
	url = "https://www.aclweb.org/anthology/J15-1001",
	doi = "10.1162/COLI_a_00206",
	pages = "1--20",
}
@inproceedings{chan-fan-2019-recurrent,
	title = "A Recurrent {BERT}-based Model for Question Generation",
	author = "Chan, Ying-Hong  and Fan, Yao-Chung",
	booktitle = "Proceedings of the 2nd Workshop on Machine Reading for Question Answering",
	month = nov,
	year = "2019",
	address = "Hong Kong, China",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D19-5821",
	doi = "10.18653/v1/D19-5821",
	pages = "154--162",
	abstract = "In this study, we investigate the employment of the pre-trained BERT language model to tackle question generation tasks. We introduce three neural architectures built on top of BERT for question generation tasks. The first one is a straightforward BERT employment, which reveals the defects of directly using BERT for text generation. Accordingly, we propose another two models by restructuring our BERT employment into a sequential manner for taking information from previous decoded results. Our models are trained and evaluated on the recent question-answering dataset SQuAD. Experiment results show that our best model yields state-of-the-art performance which advances the BLEU 4 score of the existing best models from 16.85 to 22.17.",
}

@inproceedings{duan2017question,
	title = "Question Generation for Question Answering",
	author = "Duan, Nan  and Tang, Duyu  and Chen, Peng  and Zhou, Ming",
	booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
	month = sep,
	year = "2017",
	address = "Copenhagen, Denmark",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D17-1090",
	doi = "10.18653/v1/D17-1090",
	pages = "866--874",
	abstract = "This paper presents how to generate questions from given passages using neural networks, where large scale QA pairs are automatically crawled and processed from Community-QA website, and used as training data. The contribution of the paper is 2-fold: First, two types of question generation approaches are proposed, one is a retrieval-based method using convolution neural network (CNN), the other is a generation-based method using recurrent neural network (RNN); Second, we show how to leverage the generated questions to improve existing question answering systems. We evaluate our question generation method for the answer sentence selection task on three benchmark datasets, including SQuAD, MS MARCO, and WikiQA. Experimental results show that, by using generated questions as an extra signal, significant QA improvement can be achieved.",
}

@inproceedings{tang-etal-2018-self,
	title = "Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures",
	author = "Tang, Gongbo  and Muller, Mathias  and Rios, Annette  and Sennrich, Rico",
	booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
	month = nov,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D18-1458",
	doi = "10.18653/v1/D18-1458",
	pages = "4263--4272",
	abstract = "Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in neural machine translation. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks: subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2) self-attentional networks perform distinctly better than RNNs and CNNs on word sense disambiguation.",
}

@inproceedings{chan-fan-2019-bert,
	title = "{BERT} for Question Generation",
	author = "Chan, Ying-Hong  and
	Fan, Yao-Chung",
	booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
	month = nov,
	year = "2019",
	address = "Tokyo, Japan",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W19-8624",
	doi = "10.18653/v1/W19-8624",
	pages = "173--177",
	abstract = "In this study, we investigate the employment of the pre-trained BERT language model to tackle question generation tasks. We introduce two neural architectures built on top of BERT for question generation tasks. The first one is a straightforward BERT employment, which reveals the defects of directly using BERT for text generation. And, the second one remedies the first one by restructuring the BERT employment into a sequential manner for taking information from previous decoded results. Our models are trained and evaluated on the question-answering dataset SQuAD. Experiment results show that our best model yields state-of-the-art performance which advances the BLEU4 score of existing best models from 16.85 to 18.91.",
}

@inproceedings{nema-khapra-2018-towards,
	title = "Towards a Better Metric for Evaluating Question Generation Systems",
	author = "Nema, Preksha  and
	Khapra, Mitesh M.",
	booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
	month = nov,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D18-1429",
	doi = "10.18653/v1/D18-1429",
	pages = "3950--3959",
	abstract = "There has always been criticism for using $n$-gram based similarity metrics, such as BLEU, NIST, \textit{etc}, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, \textit{etc}. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on \textit{answerability} of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, \textit{etc}. In this work, we show that current automatic evaluation metrics based on $n$-gram similarity do not always correlate well with human judgments about \textit{answerability} of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture \textit{answerability} and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available.",
}

@software{stefan_schweter_2020_3770924,
	author       = {Stefan Schweter},
	title        = {BERTurk - BERT models for Turkish},
	month        = apr,
	year         = 2020,
	publisher    = {Zenodo},
	version      = {1.0.0},
	doi          = {10.5281/zenodo.3770924},
	url          = {https://doi.org/10.5281/zenodo.3770924}
}

@misc{vaswani2017attention,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@phdthesis{rosasco_question_2020,
	title = {Question {Generation} con {BERT}},
	url = {https://github.com/andrew-r96/BertQuestionGeneration/blob/master/HLT_Report.pdf},
	school = {Universit√† di Pisa, Human Language Technologies},
	author = {Rosasco, Andrea},
	month = may,
	year = {2020},
}

@misc{zhang2019addressing,
	title={Addressing Semantic Drift in Question Generation for Semi-Supervised Question Answering}, 
	author={Shiyue Zhang and Mohit Bansal},
	year={2019},
	eprint={1909.06356},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@misc{rajpurkar2016squad,
	title={SQuAD: 100,000+ Questions for Machine Comprehension of Text}, 
	author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
	year={2016},
	eprint={1606.05250},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
